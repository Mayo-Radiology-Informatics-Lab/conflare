"""
Retrieval Augmented Generation (RAG) utilities.
"""

from typing import Callable
import chromadb

from utils.prompts import RAG_QA_PROMPT

class SimpleRetrievalQA:
    "Creates an object to do RAG based QA using an HF or OpenAI model"

    def __init__(
        self,
        qa_pipeline: Callable,
        vector_db: chromadb.Collection,
    ) -> None:
        """
        Args:
            qa_pipeline (Callable): The QA pipeline to be used; can be HF or OpenAI Callable pipeline.
            vector_db (chromadb.Collection): The collection of vectors for the database.
        """
        self.vector_db = vector_db
        self.qa_pipeline = qa_pipeline

    def __call__(self, question: str, topk: int = 3, retuen_retrieved_chunks: bool = True) -> str:
        """
        A function that takes a question, retrieves documents, generates context, creates a prompt, 
        and gets a response from a QA pipeline. Returns the response and retrieved documents based on the flag.
        
        Parameters:
            question (str): The question to be answered.
            topk (int): Number of documents to retrieve (default is 3).
            retuen_retrieved_chunks (bool): Flag to indicate whether to return retrieved documents along with the response (default is True).
        
        Returns:
            str: The response generated by the QA pipeline.
            list: Retrieved documents based on the flag.
        """
        retrieved_docs = self.vector_db.query(query_texts=question, n_results=topk)["documents"][0]
        context = "\n\n".join(retrieved_docs)
        prompt = RAG_QA_PROMPT.format(context=context, question=question)
        response = self.qa_pipeline(prompt)
        if retuen_retrieved_chunks:
            return response, retrieved_docs
        else:
            return response